"use strict";(globalThis.webpackChunkfrontend_book=globalThis.webpackChunkfrontend_book||[]).push([[966],{7393(e,n,s){s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"modules/ros2-robotics/python-ai-examples","title":"Python AI Examples for Robotics","description":"Overview","source":"@site/docs/modules/ros2-robotics/python-ai-examples.md","sourceDirName":"modules/ros2-robotics","slug":"/modules/ros2-robotics/python-ai-examples","permalink":"/docs/modules/ros2-robotics/python-ai-examples","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/ros2-robotics/python-ai-examples.md","tags":[],"version":"current","frontMatter":{}}');var i=s(4848),t=s(8453);const o={},r="Python AI Examples for Robotics",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Example 1: Simple Obstacle Avoidance AI Agent",id:"example-1-simple-obstacle-avoidance-ai-agent",level:2},{value:"Example 2: AI Agent with Basic Path Planning",id:"example-2-ai-agent-with-basic-path-planning",level:2},{value:"Example 3: Integration with Machine Learning",id:"example-3-integration-with-machine-learning",level:2},{value:"Example 4: Service-Based AI Agent",id:"example-4-service-based-ai-agent",level:2},{value:"Running the Examples",id:"running-the-examples",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"python-ai-examples-for-robotics",children:"Python AI Examples for Robotics"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This document provides practical Python code examples that demonstrate how to build intelligent control nodes using rclpy and bridge AI logic to robot controllers."}),"\n",(0,i.jsx)(n.h2,{id:"example-1-simple-obstacle-avoidance-ai-agent",children:"Example 1: Simple Obstacle Avoidance AI Agent"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist\nimport numpy as np\n\n\nclass ObstacleAvoidanceAgent(Node):\n    def __init__(self):\n        super().__init__('obstacle_avoidance_agent')\n\n        # Create subscription for laser scan data\n        self.scan_subscription = self.create_subscription(\n            LaserScan,\n            'scan',\n            self.scan_callback,\n            10\n        )\n\n        # Create publisher for velocity commands\n        self.cmd_publisher = self.create_publisher(Twist, 'cmd_vel', 10)\n\n        # Timer for AI decision making\n        self.timer = self.create_timer(0.1, self.ai_decision_callback)\n\n        # Parameters\n        self.min_distance_threshold = 1.0  # meters\n        self.linear_speed = 0.3  # m/s\n        self.angular_speed = 0.8  # rad/s\n\n        self.latest_scan = None\n        self.get_logger().info('Obstacle Avoidance Agent initialized')\n\n    def scan_callback(self, msg):\n        \"\"\"Process incoming laser scan data\"\"\"\n        self.latest_scan = msg\n\n    def ai_decision_callback(self):\n        \"\"\"Main AI decision-making function\"\"\"\n        if self.latest_scan is None:\n            return\n\n        # Process scan data to detect obstacles\n        min_distance = min(self.latest_scan.ranges)\n\n        cmd = Twist()\n\n        if min_distance < self.min_distance_threshold:\n            # Obstacle detected - turn away\n            cmd.linear.x = 0.0\n            cmd.angular.z = self.angular_speed\n            self.get_logger().info('Obstacle detected - turning')\n        else:\n            # Path clear - move forward\n            cmd.linear.x = self.linear_speed\n            cmd.angular.z = 0.0\n            self.get_logger().info('Path clear - moving forward')\n\n        # Publish command\n        self.cmd_publisher.publish(cmd)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = ObstacleAvoidanceAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"example-2-ai-agent-with-basic-path-planning",children:"Example 2: AI Agent with Basic Path Planning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom geometry_msgs.msg import Twist, Point\nfrom nav_msgs.msg import Odometry\nimport numpy as np\nimport math\n\n\nclass PathPlanningAgent(Node):\n    def __init__(self):\n        super().__init__(\'path_planning_agent\')\n\n        # Subscriptions\n        self.scan_subscription = self.create_subscription(\n            LaserScan,\n            \'scan\',\n            self.scan_callback,\n            10\n        )\n\n        self.odom_subscription = self.create_subscription(\n            Odometry,\n            \'odom\',\n            self.odom_callback,\n            10\n        )\n\n        # Publisher\n        self.cmd_publisher = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        # Timer\n        self.timer = self.create_timer(0.1, self.ai_decision_callback)\n\n        # Goal position (x, y)\n        self.goal = Point()\n        self.goal.x = 5.0\n        self.goal.y = 5.0\n\n        # Robot state\n        self.current_position = Point()\n        self.current_yaw = 0.0\n\n        # AI parameters\n        self.linear_speed = 0.3\n        self.angular_speed = 0.5\n        self.goal_tolerance = 0.5\n        self.obstacle_threshold = 1.0\n\n        self.latest_scan = None\n        self.reached_goal = False\n\n    def scan_callback(self, msg):\n        """Process laser scan data"""\n        self.latest_scan = msg\n\n    def odom_callback(self, msg):\n        """Process odometry data to get robot position and orientation"""\n        self.current_position.x = msg.pose.pose.position.x\n        self.current_position.y = msg.pose.pose.position.y\n\n        # Convert quaternion to yaw\n        orientation = msg.pose.pose.orientation\n        self.current_yaw = math.atan2(\n            2 * (orientation.w * orientation.z + orientation.x * orientation.y),\n            1 - 2 * (orientation.y * orientation.y + orientation.z * orientation.z)\n        )\n\n    def calculate_distance_to_goal(self):\n        """Calculate Euclidean distance to goal"""\n        dx = self.goal.x - self.current_position.x\n        dy = self.goal.y - self.current_position.y\n        return math.sqrt(dx * dx + dy * dy)\n\n    def calculate_angle_to_goal(self):\n        """Calculate angle to goal in robot\'s frame"""\n        dx = self.goal.x - self.current_position.x\n        dy = self.goal.y - self.current_position.y\n        goal_angle = math.atan2(dy, dx)\n        return goal_angle - self.current_yaw\n\n    def ai_decision_callback(self):\n        """Path planning AI decision making"""\n        if self.latest_scan is None:\n            return\n\n        distance_to_goal = self.calculate_distance_to_goal()\n\n        if distance_to_goal < self.goal_tolerance:\n            self.reached_goal = True\n            cmd = Twist()\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.0\n            self.cmd_publisher.publish(cmd)\n            self.get_logger().info(\'Goal reached!\')\n            return\n\n        # Check for obstacles\n        min_distance = min(self.latest_scan.ranges)\n\n        cmd = Twist()\n\n        if min_distance < self.obstacle_threshold:\n            # Obstacle detected - turn away\n            cmd.linear.x = 0.0\n            cmd.angular.z = self.angular_speed\n            self.get_logger().info(\'Obstacle detected - turning\')\n        else:\n            # Move toward goal\n            angle_to_goal = self.calculate_angle_to_goal()\n\n            # Proportional controller for angle\n            cmd.angular.z = max(-self.angular_speed, min(self.angular_speed, 2.0 * angle_to_goal))\n            cmd.linear.x = self.linear_speed * max(0.0, math.cos(angle_to_goal))\n\n            self.get_logger().info(f\'Moving toward goal, angle: {math.degrees(angle_to_goal):.2f}\xb0\')\n\n        self.cmd_publisher.publish(cmd)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = PathPlanningAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"example-3-integration-with-machine-learning",children:"Example 3: Integration with Machine Learning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import Twist\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\n\nclass MLVisionAgent(Node):\n    def __init__(self):\n        super().__init__(\'ml_vision_agent\')\n\n        # Create subscription for camera images\n        self.image_subscription = self.create_subscription(\n            Image,\n            \'camera/image_raw\',\n            self.image_callback,\n            10\n        )\n\n        # Create publisher for velocity commands\n        self.cmd_publisher = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        # Timer for AI processing\n        self.timer = self.create_timer(0.1, self.ai_decision_callback)\n\n        # CV Bridge for image processing\n        self.bridge = CvBridge()\n\n        # State variables\n        self.latest_image = None\n        self.object_detected = False\n        self.object_position = None  # Normalized position (-1.0 to 1.0)\n\n        self.get_logger().info(\'ML Vision Agent initialized\')\n\n    def image_callback(self, msg):\n        """Process incoming camera image"""\n        try:\n            # Convert ROS Image message to OpenCV image\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n\n            # Process image to detect objects (simplified example)\n            self.object_detected, self.object_position = self.detect_object(cv_image)\n\n            # Store the image for potential use in AI processing\n            self.latest_image = cv_image\n\n        except Exception as e:\n            self.get_logger().error(f\'Error processing image: {e}\')\n\n    def detect_object(self, image):\n        """Simple object detection using color thresholding"""\n        # Convert BGR to HSV\n        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n        # Define range for red color (example)\n        lower_red = np.array([0, 50, 50])\n        upper_red = np.array([10, 255, 255])\n        mask1 = cv2.inRange(hsv, lower_red, upper_red)\n\n        lower_red = np.array([170, 50, 50])\n        upper_red = np.array([180, 255, 255])\n        mask2 = cv2.inRange(hsv, lower_red, upper_red)\n\n        mask = mask1 + mask2\n\n        # Find contours\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        if contours:\n            # Find the largest contour\n            largest_contour = max(contours, key=cv2.contourArea)\n\n            if cv2.contourArea(largest_contour) > 500:  # Minimum area threshold\n                # Get the center of the contour\n                M = cv2.moments(largest_contour)\n                if M["m00"] != 0:\n                    cx = int(M["m10"] / M["m00"])\n                    # Normalize position to -1.0 (left) to 1.0 (right)\n                    normalized_x = (cx - image.shape[1] / 2) / (image.shape[1] / 2)\n                    return True, normalized_x\n\n        return False, None\n\n    def ai_decision_callback(self):\n        """AI decision making based on vision input"""\n        cmd = Twist()\n\n        if self.object_detected and self.object_position is not None:\n            # Object detected - move toward it\n            cmd.linear.x = 0.3  # Move forward\n\n            # Turn toward object\n            cmd.angular.z = -0.5 * self.object_position  # Negative because of coordinate system\n\n            self.get_logger().info(f\'Object detected at position: {self.object_position:.2f}\')\n        else:\n            # No object detected - search pattern\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.3  # Slow turn to search\n\n            self.get_logger().info(\'Searching for object...\')\n\n        self.cmd_publisher.publish(cmd)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = MLVisionAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"example-4-service-based-ai-agent",children:"Example 4: Service-Based AI Agent"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom example_interfaces.srv import Trigger\nfrom geometry_msgs.msg import Twist\nimport random\n\n\nclass ServiceBasedAIAgent(Node):\n    def __init__(self):\n        super().__init__(\'service_based_ai_agent\')\n\n        # Publisher for commands\n        self.cmd_publisher = self.create_publisher(Twist, \'cmd_vel\', 10)\n\n        # Service to request AI decisions\n        self.decision_service = self.create_service(\n            Trigger,\n            \'request_ai_decision\',\n            self.decision_callback\n        )\n\n        # Publisher for AI status\n        self.status_publisher = self.create_publisher(String, \'ai_status\', 10)\n\n        # AI state\n        self.ai_enabled = True\n        self.behavior_mode = "explore"  # explore, avoid, follow\n\n        self.get_logger().info(\'Service-Based AI Agent initialized\')\n\n    def decision_callback(self, request, response):\n        """Handle AI decision requests"""\n        if not self.ai_enabled:\n            response.success = False\n            response.message = "AI agent is disabled"\n            return response\n\n        # Generate a decision based on current mode\n        cmd = self.generate_decision()\n        self.cmd_publisher.publish(cmd)\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f"Decision made in {self.behavior_mode} mode"\n        self.status_publisher.publish(status_msg)\n\n        response.success = True\n        response.message = f"Decision executed: {self.behavior_mode}"\n        return response\n\n    def generate_decision(self):\n        """Generate a decision based on current behavior mode"""\n        cmd = Twist()\n\n        if self.behavior_mode == "explore":\n            cmd.linear.x = 0.3\n            cmd.angular.z = random.uniform(-0.5, 0.5)\n        elif self.behavior_mode == "avoid":\n            cmd.linear.x = 0.0\n            cmd.angular.z = 0.8\n        elif self.behavior_mode == "follow":\n            cmd.linear.x = 0.5\n            cmd.angular.z = 0.0\n\n        return cmd\n\n    def change_behavior(self, new_mode):\n        """Change the AI agent\'s behavior mode"""\n        if new_mode in ["explore", "avoid", "follow"]:\n            self.behavior_mode = new_mode\n            self.get_logger().info(f\'Changed behavior mode to: {new_mode}\')\n        else:\n            self.get_logger().warn(f\'Invalid behavior mode: {new_mode}\')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = ServiceBasedAIAgent()\n\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        agent.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"running-the-examples",children:"Running the Examples"}),"\n",(0,i.jsx)(n.p,{children:"To run these examples:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Create a new ROS 2 package"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/ros2_ws/src/my_ai_agents\ncd ~/ros2_ws/src/my_ai_agents\nros2 pkg create --build-type ament_python my_ai_agents\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Copy the example code"})," into appropriate Python files in your package"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Update setup.py"})," to include the executables:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from setuptools import find_packages, setup\n\npackage_name = 'my_ai_agents'\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='Your Name',\n    maintainer_email='your.email@example.com',\n    description='AI agents for robotics',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'obstacle_avoidance = my_ai_agents.obstacle_avoidance:main',\n            'path_planning = my_ai_agents.path_planning:main',\n            'ml_vision = my_ai_agents.ml_vision:main',\n            'service_agent = my_ai_agents.service_agent:main',\n        ],\n    },\n)\n"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Build and run"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select my_ai_agents\nsource install/setup.bash\nros2 run my_ai_agents obstacle_avoidance\n"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"These examples demonstrate different approaches to implementing AI agents with rclpy, from simple reactive behaviors to more complex path planning and machine learning integration."})]})}function m(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>o,x:()=>r});var a=s(6540);const i={},t=a.createContext(i);function o(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);