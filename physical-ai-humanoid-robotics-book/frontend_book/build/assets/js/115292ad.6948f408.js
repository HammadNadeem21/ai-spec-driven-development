"use strict";(globalThis.webpackChunkfrontend_book=globalThis.webpackChunkfrontend_book||[]).push([[46],{2403(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"modules/vla/chapter-3-autonomous-humanoid","title":"Chapter 3: Capstone \u2013 The Autonomous Humanoid","description":"Overview","source":"@site/docs/modules/vla/chapter-3-autonomous-humanoid.md","sourceDirName":"modules/vla","slug":"/modules/vla/chapter-3-autonomous-humanoid","permalink":"/docs/modules/vla/chapter-3-autonomous-humanoid","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/modules/vla/chapter-3-autonomous-humanoid.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Chapter 3: Capstone \u2013 The Autonomous Humanoid"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Language-Driven Cognitive Planning","permalink":"/docs/modules/vla/chapter-2-cognitive-planning"}}');var i=t(4848),o=t(8453);const s={sidebar_position:3,title:"Chapter 3: Capstone \u2013 The Autonomous Humanoid"},r="Chapter 3: Capstone \u2013 The Autonomous Humanoid",l={},c=[{value:"Overview",id:"overview",level:2},{value:"End-to-End VLA Architecture",id:"end-to-end-vla-architecture",level:2},{value:"System Architecture Diagram",id:"system-architecture-diagram",level:3},{value:"VLA Orchestrator Implementation",id:"vla-orchestrator-implementation",level:3},{value:"Navigation, Perception, and Manipulation Flow",id:"navigation-perception-and-manipulation-flow",level:2},{value:"Coordinated Action Execution",id:"coordinated-action-execution",level:3},{value:"Orchestrating Speech, Planning, and Execution in Simulation",id:"orchestrating-speech-planning-and-execution-in-simulation",level:2},{value:"Simulation Integration",id:"simulation-integration",level:3},{value:"Main VLA System Launch",id:"main-vla-system-launch",level:3},{value:"Implementation Best Practices",id:"implementation-best-practices",level:2},{value:"Plan Adaptation for Unexpected Situations",id:"plan-adaptation-for-unexpected-situations",level:3},{value:"Comprehensive Error Handling",id:"comprehensive-error-handling",level:3},{value:"Launch File for Complete VLA System",id:"launch-file-for-complete-vla-system",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-3-capstone--the-autonomous-humanoid",children:"Chapter 3: Capstone \u2013 The Autonomous Humanoid"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This capstone chapter brings together all the components from the previous chapters to create a complete Vision-Language-Action (VLA) system. We'll implement the end-to-end architecture that orchestrates speech processing, cognitive planning, and action execution in simulation environments."}),"\n",(0,i.jsx)(n.h2,{id:"end-to-end-vla-architecture",children:"End-to-End VLA Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The complete VLA system integrates voice processing, cognitive planning, and action execution into a unified architecture that enables autonomous humanoid behavior."}),"\n",(0,i.jsx)(n.h3,{id:"system-architecture-diagram",children:"System Architecture Diagram"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User Voice    \u2502\u2500\u2500\u2500\u25b6\u2502 Voice Processing \u2502\u2500\u2500\u2500\u25b6\u2502 Cognitive Planner\u2502\n\u2502   Command       \u2502    \u2502   (Whisper)      \u2502    \u2502     (LLM)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Simulation     \u2502\u25c0\u2500\u2500\u2500\u2502  VLA Orchestrator\u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502 Environment     \u2502    \u2502                  \u2502                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n                             \u2502                                       \u2502\n                             \u25bc                                       \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Action Executor \u2502                   \u2502 Safety Validator\u2502\n                    \u2502                  \u2502                   \u2502                 \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Robot Control   \u2502\n                    \u2502    Interface     \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsx)(n.h3,{id:"vla-orchestrator-implementation",children:"VLA Orchestrator Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom sensor_msgs.msg import AudioData\nfrom action_msgs.msg import GoalStatus\nimport json\nimport time\nfrom typing import Dict, Any, Optional\n\n@dataclass\nclass SimulationState:\n    """Represents the current state of the simulation environment"""\n    id: str\n    robot_pose: Dict[str, float]  # x, y, z, qx, qy, qz, qw\n    environment_objects: List[Dict[str, Any]]\n    sensor_data: Dict[str, Any]\n    timestamp: str\n\nclass VLAOrchestrator(Node):\n    def __init__(self):\n        super().__init__(\'vla_orchestrator\')\n\n        # Publishers for different system components\n        self.voice_command_publisher = self.create_publisher(\n            String,\n            \'vla/voice_commands\',\n            10\n        )\n\n        self.action_plan_publisher = self.create_publisher(\n            String,\n            \'vla/action_plans\',\n            10\n        )\n\n        self.execution_status_publisher = self.create_publisher(\n            String,\n            \'vla/execution_status\',\n            10\n        )\n\n        # Subscribers for system feedback\n        self.voice_subscriber = self.create_subscription(\n            String,\n            \'voice_commands\',\n            self.voice_command_callback,\n            10\n        )\n\n        self.simulation_state_subscriber = self.create_subscription(\n            String,\n            \'simulation/state\',\n            self.simulation_state_callback,\n            10\n        )\n\n        # Initialize components\n        self.planning_system = CognitivePlanningSystem()\n        self.safety_validator = SafetyConstraintValidator()\n        self.current_state = SimulationState(\n            id="initial",\n            robot_pose={"x": 0.0, "y": 0.0, "z": 0.0, "qx": 0.0, "qy": 0.0, "qz": 0.0, "qw": 1.0},\n            environment_objects=[],\n            sensor_data={},\n            timestamp=str(time.time())\n        )\n\n        # Active plans tracking\n        self.active_plans = {}\n        self.plan_execution_timer = self.create_timer(0.1, self.execute_plan_step)\n\n    def voice_command_callback(self, msg: String):\n        """Handle incoming voice commands"""\n        command_text = msg.data\n        self.get_logger().info(f"Received voice command: {command_text}")\n\n        # Process the command through the VLA pipeline\n        self.process_voice_command(command_text)\n\n    def simulation_state_callback(self, msg: String):\n        """Update current simulation state"""\n        try:\n            state_data = json.loads(msg.data)\n            self.current_state = SimulationState(\n                id=state_data.get("id", self.current_state.id),\n                robot_pose=state_data.get("robot_pose", self.current_state.robot_pose),\n                environment_objects=state_data.get("environment_objects", self.current_state.environment_objects),\n                sensor_data=state_data.get("sensor_data", self.current_state.sensor_data),\n                timestamp=state_data.get("timestamp", self.current_state.timestamp)\n            )\n        except json.JSONDecodeError:\n            self.get_logger().warn("Invalid simulation state message")\n\n    def process_voice_command(self, command_text: str):\n        """Process a voice command through the complete VLA pipeline"""\n        try:\n            # Step 1: Decompose task using cognitive planning\n            task_plan = self.planning_system.decompose_task(command_text)\n\n            if task_plan.status == "failed":\n                self.get_logger().error("Task decomposition failed")\n                self.publish_execution_status("failed", "Task decomposition failed")\n                return\n\n            # Step 2: Validate safety constraints\n            if not self.validate_plan_safety(task_plan):\n                self.get_logger().error("Plan failed safety validation")\n                self.publish_execution_status("failed", "Safety validation failed")\n                return\n\n            # Step 3: Publish the validated plan for execution\n            self.publish_action_plan(task_plan)\n\n            # Track the plan for execution monitoring\n            self.active_plans[task_plan.id] = task_plan\n\n            self.get_logger().info(f"Successfully processed command: {command_text}")\n\n        except Exception as e:\n            self.get_logger().error(f"Error processing voice command: {e}")\n            self.publish_execution_status("failed", str(e))\n\n    def validate_plan_safety(self, task_plan: TaskPlan) -> bool:\n        """Validate the entire task plan for safety"""\n        for action in task_plan.actions:\n            if not self.safety_validator.validate_action(action, self.current_state.__dict__):\n                return False\n        return True\n\n    def publish_action_plan(self, task_plan: TaskPlan):\n        """Publish the action plan for execution"""\n        plan_msg = String()\n        plan_msg.data = json.dumps({\n            "plan_id": task_plan.id,\n            "original_command": task_plan.original_command,\n            "actions": [\n                {\n                    "id": action.id,\n                    "type": action.type,\n                    "parameters": action.parameters,\n                    "dependencies": action.dependencies,\n                    "timeout": action.timeout,\n                    "priority": action.priority\n                } for action in task_plan.actions\n            ],\n            "constraints": task_plan.constraints\n        })\n\n        self.action_plan_publisher.publish(plan_msg)\n\n    def publish_execution_status(self, status: str, message: str = ""):\n        """Publish execution status updates"""\n        status_msg = String()\n        status_msg.data = json.dumps({\n            "status": status,\n            "message": message,\n            "timestamp": time.time()\n        })\n\n        self.execution_status_publisher.publish(status_msg)\n\n    def execute_plan_step(self):\n        """Execute the next step in active plans"""\n        for plan_id, plan in list(self.active_plans.items()):\n            if plan.status == "executing":\n                next_action = self.get_next_action(plan)\n                if next_action:\n                    # Execute the action\n                    self.execute_action(next_action)\n                elif self.is_plan_complete(plan):\n                    # Plan is complete\n                    plan.status = "completed"\n                    self.publish_execution_status("completed", f"Plan {plan_id} completed")\n                    del self.active_plans[plan_id]\n\n    def get_next_action(self, plan: TaskPlan) -> Optional[ActionSequence]:\n        """Get the next executable action from the plan"""\n        # Find actions that are not yet executed and have satisfied dependencies\n        for action in plan.actions:\n            if self.is_action_ready(action, plan):\n                return action\n        return None\n\n    def is_action_ready(self, action: ActionSequence, plan: TaskPlan) -> bool:\n        """Check if an action is ready to execute based on dependencies"""\n        # Check if all dependencies are completed\n        for dep_id in action.dependencies:\n            dep_action = next((a for a in plan.actions if a.id == dep_id), None)\n            if dep_action and dep_action.status != "completed":\n                return False\n        return True\n\n    def is_plan_complete(self, plan: TaskPlan) -> bool:\n        """Check if all actions in the plan are completed"""\n        completed_count = sum(1 for action in plan.actions if action.status == "completed")\n        return completed_count == len(plan.actions)\n\n    def execute_action(self, action: ActionSequence):\n        """Execute a single action"""\n        # Map to ROS 2 action and execute\n        action_mapper = ROS2ActionMapper()\n        ros_action = action_mapper.map_to_ros2(action)\n\n        # Publish the action to the appropriate interface\n        # This would involve calling ROS 2 services or publishing to topics\n        self.get_logger().info(f"Executing action: {action.id} of type {action.type}")\n\n        # Update action status (in a real system, this would be updated based on execution feedback)\n        action.status = "executing"\n'})}),"\n",(0,i.jsx)(n.h2,{id:"navigation-perception-and-manipulation-flow",children:"Navigation, Perception, and Manipulation Flow"}),"\n",(0,i.jsx)(n.p,{children:"The complete VLA system orchestrates multiple robot capabilities to achieve complex tasks. Let's examine how navigation, perception, and manipulation work together."}),"\n",(0,i.jsx)(n.h3,{id:"coordinated-action-execution",children:"Coordinated Action Execution"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class ActionFlowController:\n    def __init__(self, orchestrator: VLAOrchestrator):\n        self.orchestrator = orchestrator\n        self.action_sequences = {\n            "fetch_object": self._execute_fetch_object_sequence,\n            "navigate_to_location": self._execute_navigation_sequence,\n            "inspect_area": self._execute_inspection_sequence\n        }\n\n    def _execute_fetch_object_sequence(self, parameters: Dict[str, Any]):\n        """Execute a complete fetch object sequence: navigate -> perceive -> manipulate -> return"""\n        object_name = parameters.get("object_name", "")\n        destination = parameters.get("destination", {})\n\n        # Step 1: Navigate to object location\n        nav_action = ActionSequence(\n            id=f"nav_to_{object_name}",\n            type="navigation",\n            parameters={"pose": parameters.get("object_pose", {})},\n            dependencies=[],\n            timeout=30.0,\n            priority=1\n        )\n\n        # Step 2: Perceive the object (after navigation)\n        perceive_action = ActionSequence(\n            id=f"perceive_{object_name}",\n            type="perception",\n            parameters={\n                "camera": "head_camera",\n                "object_types": [object_name]\n            },\n            dependencies=[nav_action.id],\n            timeout=10.0,\n            priority=2\n        )\n\n        # Step 3: Manipulate the object (after perception)\n        manipulate_action = ActionSequence(\n            id=f"manipulate_{object_name}",\n            type="manipulation",\n            parameters={\n                "target_pose": parameters.get("object_pose", {}),\n                "object_id": object_name\n            },\n            dependencies=[perceive_action.id],\n            timeout=20.0,\n            priority=3\n        )\n\n        # Step 4: Navigate back to destination (after manipulation)\n        return_action = ActionSequence(\n            id=f"return_to_{destination.get(\'name\', \'destination\')}",\n            type="navigation",\n            parameters={"pose": destination},\n            dependencies=[manipulate_action.id],\n            timeout=30.0,\n            priority=4\n        )\n\n        # Create and execute the complete plan\n        complete_plan = TaskPlan(\n            id=f"fetch_plan_{int(time.time())}",\n            original_command=f"Fetch {object_name} and bring it to destination",\n            actions=[nav_action, perceive_action, manipulate_action, return_action],\n            constraints=[],\n            status="pending",\n            created_at=time.time()\n        )\n\n        # Validate and execute the plan\n        if self.orchestrator.validate_plan_safety(complete_plan):\n            self.orchestrator.active_plans[complete_plan.id] = complete_plan\n            complete_plan.status = "executing"\n            self.orchestrator.publish_action_plan(complete_plan)\n\n    def _execute_navigation_sequence(self, parameters: Dict[str, Any]):\n        """Execute navigation sequence with safety checks"""\n        target_pose = parameters.get("pose", {})\n\n        # Validate navigation safety\n        safety_check = self.orchestrator.safety_validator._validate_navigation_safety(\n            ActionSequence(\n                id="temp_nav",\n                type="navigation",\n                parameters={"pose": target_pose},\n                dependencies=[],\n                timeout=10.0,\n                priority=1\n            ),\n            self.orchestrator.current_state.__dict__\n        )\n\n        if safety_check:\n            # Execute navigation\n            nav_action = ActionSequence(\n                id=f"nav_{int(time.time())}",\n                type="navigation",\n                parameters={"pose": target_pose},\n                dependencies=[],\n                timeout=30.0,\n                priority=1\n            )\n\n            plan = TaskPlan(\n                id=f"nav_plan_{int(time.time())}",\n                original_command=f"Navigate to {target_pose}",\n                actions=[nav_action],\n                constraints=[],\n                status="executing",\n                created_at=time.time()\n            )\n\n            self.orchestrator.active_plans[plan.id] = plan\n            self.orchestrator.publish_action_plan(plan)\n\n    def _execute_inspection_sequence(self, parameters: Dict[str, Any]):\n        """Execute inspection sequence: navigate -> perceive -> analyze"""\n        area_pose = parameters.get("area_pose", {})\n        object_types = parameters.get("object_types", [])\n\n        # Navigate to inspection area\n        nav_action = ActionSequence(\n            id=f"nav_inspect_{int(time.time())}",\n            type="navigation",\n            parameters={"pose": area_pose},\n            dependencies=[],\n            timeout=30.0,\n            priority=1\n        )\n\n        # Perceive objects in the area\n        perceive_action = ActionSequence(\n            id=f"perceive_area_{int(time.time())}",\n            type="perception",\n            parameters={\n                "camera": "head_camera",\n                "object_types": object_types\n            },\n            dependencies=[nav_action.id],\n            timeout=15.0,\n            priority=2\n        )\n\n        # Analyze results (could involve more complex cognitive processing)\n        analyze_action = ActionSequence(\n            id=f"analyze_{int(time.time())}",\n            type="communication",  # For reporting results\n            parameters={\n                "text": "Analysis complete",\n                "result_topic": "inspection_results"\n            },\n            dependencies=[perceive_action.id],\n            timeout=5.0,\n            priority=3\n        )\n\n        plan = TaskPlan(\n            id=f"inspect_plan_{int(time.time())}",\n            original_command=f"Inspect area at {area_pose} for {object_types}",\n            actions=[nav_action, perceive_action, analyze_action],\n            constraints=[],\n            status="executing",\n            created_at=time.time()\n        )\n\n        if self.orchestrator.validate_plan_safety(plan):\n            self.orchestrator.active_plans[plan.id] = plan\n            self.orchestrator.publish_action_plan(plan)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"orchestrating-speech-planning-and-execution-in-simulation",children:"Orchestrating Speech, Planning, and Execution in Simulation"}),"\n",(0,i.jsx)(n.p,{children:"The complete VLA system operates in a simulation environment where all components work together seamlessly."}),"\n",(0,i.jsx)(n.h3,{id:"simulation-integration",children:"Simulation Integration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class VLASimulationIntegrator:\n    def __init__(self, orchestrator: VLAOrchestrator):\n        self.orchestrator = orchestrator\n        self.simulation_client = None  # Would connect to Gazebo, Isaac Sim, etc.\n        self.execution_monitor = ExecutionMonitor()\n\n    def start_simulation_loop(self):\n        """Start the main simulation loop that integrates all VLA components"""\n        self.get_logger().info("Starting VLA simulation loop")\n\n        # Main loop - in a real system this would be driven by simulation callbacks\n        simulation_timer = self.create_timer(0.016, self.simulation_step)  # ~60 Hz\n\n    def simulation_step(self):\n        """Execute one step of the simulation loop"""\n        # Update simulation state\n        self.update_simulation_state()\n\n        # Process any pending voice commands\n        self.process_pending_commands()\n\n        # Execute plan steps\n        self.orchestrator.execute_plan_step()\n\n        # Monitor execution status\n        self.execution_monitor.check_execution_status()\n\n        # Handle any exceptions or fallbacks\n        self.handle_execution_exceptions()\n\n    def update_simulation_state(self):\n        """Update the current simulation state"""\n        # In a real simulation, this would get state from the simulator\n        sim_state = {\n            "id": f"state_{int(time.time() * 1000)}",\n            "robot_pose": self.get_robot_pose(),\n            "environment_objects": self.get_environment_objects(),\n            "sensor_data": self.get_sensor_data(),\n            "timestamp": time.time()\n        }\n\n        # Publish state update\n        state_msg = String()\n        state_msg.data = json.dumps(sim_state)\n        self.orchestrator.simulation_state_publisher.publish(state_msg)\n\n    def get_robot_pose(self) -> Dict[str, float]:\n        """Get current robot pose from simulation"""\n        # This would interface with the actual simulation\n        # For now, return a mock pose\n        return {\n            "x": 0.0, "y": 0.0, "z": 0.0,\n            "qx": 0.0, "qy": 0.0, "qz": 0.0, "qw": 1.0\n        }\n\n    def get_environment_objects(self) -> List[Dict[str, Any]]:\n        """Get list of objects in the simulation environment"""\n        # This would interface with the actual simulation\n        return []\n\n    def get_sensor_data(self) -> Dict[str, Any]:\n        """Get current sensor data from simulation"""\n        # This would interface with the actual simulation\n        return {}\n\n    def process_pending_commands(self):\n        """Process any pending voice commands"""\n        # This would check for new voice commands from the voice processing system\n        pass\n\n    def handle_execution_exceptions(self):\n        """Handle any execution exceptions and trigger fallbacks"""\n        # Monitor for failed actions and trigger appropriate responses\n        for plan_id, plan in self.orchestrator.active_plans.items():\n            if plan.status == "failed":\n                self.handle_plan_failure(plan_id, plan)\n\n    def handle_plan_failure(self, plan_id: str, plan: TaskPlan):\n        """Handle plan failure with appropriate fallback strategy"""\n        self.get_logger().error(f"Plan {plan_id} failed, executing fallback")\n\n        # Implement fallback strategy\n        fallback_action = ActionSequence(\n            id=f"fallback_{plan_id}",\n            type="communication",\n            parameters={\n                "text": f"Plan {plan_id} failed, requesting assistance",\n                "priority": "high"\n            },\n            dependencies=[],\n            timeout=5.0,\n            priority=10\n        )\n\n        fallback_plan = TaskPlan(\n            id=f"fallback_plan_{plan_id}",\n            original_command=f"Fallback for failed plan {plan_id}",\n            actions=[fallback_action],\n            constraints=[],\n            status="executing",\n            created_at=time.time()\n        )\n\n        self.orchestrator.active_plans[f"fallback_{plan_id}"] = fallback_plan\n        self.orchestrator.publish_action_plan(fallback_plan)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"main-vla-system-launch",children:"Main VLA System Launch"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def main(args=None):\n    rclpy.init(args=args)\n\n    # Create the VLA orchestrator node\n    vla_orchestrator = VLAOrchestrator()\n\n    # Create the flow controller\n    flow_controller = ActionFlowController(vla_orchestrator)\n\n    # Create the simulation integrator\n    sim_integrator = VLASimulationIntegrator(vla_orchestrator)\n\n    # Start the simulation loop\n    sim_integrator.start_simulation_loop()\n\n    try:\n        # Spin the orchestrator to handle callbacks\n        rclpy.spin(vla_orchestrator)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        vla_orchestrator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementation-best-practices",children:"Implementation Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"plan-adaptation-for-unexpected-situations",children:"Plan Adaptation for Unexpected Situations"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class PlanAdaptor:\n    def __init__(self, orchestrator: VLAOrchestrator):\n        self.orchestrator = orchestrator\n\n    def adapt_plan_to_situation(self, plan_id: str, situation: Dict[str, Any]):\n        """Adapt an existing plan based on unexpected situations"""\n        if plan_id not in self.orchestrator.active_plans:\n            return\n\n        original_plan = self.orchestrator.active_plans[plan_id]\n\n        # Analyze the situation and determine adaptation needed\n        if situation.get("obstacle_detected"):\n            # Modify navigation actions to avoid obstacles\n            self._adapt_for_obstacles(original_plan, situation)\n        elif situation.get("object_not_found"):\n            # Modify perception actions to search elsewhere\n            self._adapt_for_missing_object(original_plan, situation)\n        elif situation.get("execution_failed"):\n            # Retry or find alternative approach\n            self._adapt_for_execution_failure(original_plan, situation)\n\n    def _adapt_for_obstacles(self, plan: TaskPlan, situation: Dict[str, Any]):\n        """Adapt plan for obstacle avoidance"""\n        for action in plan.actions:\n            if action.type == "navigation":\n                # Recalculate path to avoid obstacle\n                new_path = self._calculate_avoidance_path(action, situation)\n                if new_path:\n                    action.parameters["pose"] = new_path\n\n    def _adapt_for_missing_object(self, plan: TaskPlan, situation: Dict[str, Any]):\n        """Adapt plan when expected object is not found"""\n        # Add search actions before manipulation\n        search_action = ActionSequence(\n            id=f"search_{situation.get(\'object_id\', \'unknown\')}",\n            type="perception",\n            parameters={\n                "camera": "head_camera",\n                "search_pattern": "spiral",\n                "object_types": [situation.get("object_id", "unknown")]\n            },\n            dependencies=[],\n            timeout=30.0,\n            priority=2\n        )\n\n        # Insert search action before manipulation\n        manipulation_idx = next(\n            (i for i, a in enumerate(plan.actions) if a.type == "manipulation"),\n            -1\n        )\n\n        if manipulation_idx != -1:\n            # Update dependencies for manipulation action\n            plan.actions[manipulation_idx].dependencies.append(search_action.id)\n            # Insert search action\n            plan.actions.insert(manipulation_idx, search_action)\n\n    def _adapt_for_execution_failure(self, plan: TaskPlan, situation: Dict[str, Any]):\n        """Adapt plan when an action fails to execute"""\n        failed_action_id = situation.get("failed_action_id")\n\n        # Find the failed action\n        failed_action = next(\n            (a for a in plan.actions if a.id == failed_action_id),\n            None\n        )\n\n        if failed_action:\n            # Try alternative approach\n            alternative_action = self._generate_alternative_action(failed_action)\n            if alternative_action:\n                # Replace or add alternative action\n                plan.actions.append(alternative_action)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"comprehensive-error-handling",children:"Comprehensive Error Handling"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'class VLAFallbackHandler:\n    def __init__(self, orchestrator: VLAOrchestrator):\n        self.orchestrator = orchestrator\n        self.fallback_strategies = {\n            "navigation_failure": self._handle_navigation_failure,\n            "manipulation_failure": self._handle_manipulation_failure,\n            "perception_failure": self._handle_perception_failure,\n            "communication_failure": self._handle_communication_failure\n        }\n\n    def handle_action_failure(self, action: ActionSequence, error: Exception):\n        """Handle action failure with appropriate fallback"""\n        error_type = self._categorize_error(error)\n\n        if error_type in self.fallback_strategies:\n            self.fallback_strategies[error_type](action, error)\n        else:\n            self._handle_generic_failure(action, error)\n\n    def _categorize_error(self, error: Exception) -> str:\n        """Categorize error type for appropriate fallback"""\n        error_msg = str(error).lower()\n\n        if "navigation" in error_msg or "path" in error_msg:\n            return "navigation_failure"\n        elif "manipulation" in error_msg or "grasp" in error_msg:\n            return "manipulation_failure"\n        elif "perception" in error_msg or "detect" in error_msg:\n            return "perception_failure"\n        else:\n            return "generic_failure"\n\n    def _handle_navigation_failure(self, action: ActionSequence, error: Exception):\n        """Handle navigation failure with fallback strategies"""\n        self.orchestrator.get_logger().warn(f"Navigation failed: {error}")\n\n        # Try alternative path\n        alternative_action = ActionSequence(\n            id=f"alt_nav_{action.id}",\n            type="navigation",\n            parameters={**action.parameters, "alternative_path": True},\n            dependencies=action.dependencies,\n            timeout=action.timeout * 2,\n            priority=action.priority + 1\n        )\n\n        # Add to plan with higher priority\n        task_plan = self._find_plan_for_action(action.id)\n        if task_plan:\n            task_plan.actions.append(alternative_action)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"launch-file-for-complete-vla-system",children:"Launch File for Complete VLA System"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Task T035: Create complete VLA system launch file in launch/vla_system.launch.py"})}),"\n",(0,i.jsx)(n.p,{children:"Wait, I need to create this in the correct location. Based on the project structure, I should create a launch file. Let me create it:"})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>r});var a=t(6540);const i={},o=a.createContext(i);function s(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);